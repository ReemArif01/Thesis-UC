---
title: "test"
output: html_document
---

```{r}
install.packages("tidyverse")
install.packages("dplyr")
```

```{r}
library(tidyverse)
library(dplyr)
library(rvest)
library(tibble)
library(stringr)

install.packages(c("httr2", "jsonlite", "dplyr", "purrr", "stringr", "readr"))
library(httr2)
library(jsonlite)
library(dplyr)
library(purrr)
library(readr)

```

```{r}
#This where you find the list of UN decisions
##https://main.un.org/securitycouncil/en/sanctions/1267/press-releases?page=0

```
```{r}

`%||%` <- function(x, y) if (is.null(x)) y else x

path <- "/Users/reemarif/Desktop/entities.ftm.json"
out_csv <- "/Users/reemarif/Desktop/eu_fsf_organizations_only.csv"

con <- file(path, open = "r")
on.exit(close(con), add = TRUE)

rows <- list()
k <- 0
i <- 0

while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0) {
  i <- i + 1
  x <- fromJSON(line, simplifyVector = FALSE)

  if (!identical(x$schema, "Organization")) next

  ds <- unlist(x$datasets %||% x$properties$datasets %||% character(), use.names = FALSE)

  if ("eu_fsf" %in% ds) {
    k <- k + 1
    rows[[k]] <- tibble(
      id = x$id %||% NA_character_,
      name = x$caption %||% NA_character_
    )
  }

  if (i %% 50000 == 0) message("Read ", i, " lines; kept ", k, " eu_fsf orgs")
}

df_eu <- bind_rows(rows) |>
  distinct(id, name) |>
  arrange(name)

write.csv(df_eu, out_csv, row.names = FALSE)
out_csv

```

```{r}

`%||%` <- function(x, y) if (is.null(x)) y else x

folder <- "/Users/reemarif/Desktop/1st Quarter/MA Sources/Thesis-UC"
path <- file.path(folder, "entities.ftm.json")

con <- file(path, open = "r")

rows <- list()
i <- 0
k <- 0

while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0) {
  i <- i + 1
  x <- fromJSON(line, simplifyVector = FALSE)

  # keep only EU FSF organizations
  if (identical(x$schema, "Organization") && ("eu_fsf" %in% (x$properties$datasets %||% character()))) {
    k <- k + 1
    rows[[k]] <- tibble(
      id = x$id %||% NA_character_,
      name = x$caption %||% NA_character_,
      first_seen = x$properties$first_seen %||% NA_character_,
      last_seen  = x$properties$last_seen  %||% NA_character_
    )
  }

  if (i %% 5000 == 0) message("Read ", i, " lines; kept ", k, " EU FSF orgs")
}

close(con)

df <- bind_rows(rows)
write.csv(df, file.path(folder, "eu_fsf_organizations.csv"), row.names = FALSE)

test_orgs <- keep(entities, ~ .x$schema == "Organization")
length(test_orgs)
unique(unlist(map(test_orgs[1:100], ~ .x$datasets %||% character())))
```
```{r}
ath <- "/Users/reemarif/Desktop/1st Quarter/MA Sources/Thesis-UC/entities.ftm (1).json"
con <- file(path, open = "r")

n <- 0
n_org <- 0

while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0 && n < 20000) {
  n <- n + 1
  x <- fromJSON(line, simplifyVector = FALSE)
  if (identical(x$schema, "Organization")) n_org <- n_org + 1
}

close(con)
c(total_checked = n, organizations = n_org)
```
```{r}

`%||%` <- function(x, y) if (is.null(x)) y else x

path <- "/Users/reemarif/Desktop/1st Quarter/MA Sources/Thesis-UC/entities.ftm.json"
con <- file(path, open = "r")

vals <- character()
n <- 0

while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0 && n < 30000) {
  n <- n + 1
  x <- fromJSON(line, simplifyVector = FALSE)

  if (identical(x$schema, "Organization")) {
    ds <- (x$datasets %||% x$properties$datasets %||% character())

    # force to a plain character vector
    ds <- unlist(ds, use.names = FALSE)

    if (length(ds) > 0) vals <- c(vals, ds)
  }
}

close(con)

vals <- unlist(vals, use.names = FALSE)

# Now these will work
head(sort(unique(vals)), 50)
"eu_fsf" %in% vals

# Top 30 most common dataset tags
sort(table(vals), decreasing = TRUE)[1:30]


```

```{r}

`%||%` <- function(x, y) if (is.null(x)) y else x

path <- "/Users/reemarif/Desktop/1st Quarter/MA Sources/Thesis-UC/entities.ftm (1).json"
con <- file(path, open = "r")

rows <- list()
i <- 0
k <- 0

while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0) {
  i <- i + 1
  x <- fromJSON(line, simplifyVector = FALSE)

  if (identical(x$schema, "Organization")) {
    ds <- unlist(x$datasets %||% x$properties$datasets %||% character(), use.names = FALSE)

    if ("eu_fsf" %in% ds) {
      k <- k + 1
      rows[[k]] <- tibble(
        id = x$id %||% NA_character_,
        name = x$caption %||% NA_character_,
        datasets = paste(ds, collapse = "; ")
      )
    }
  }

  if (i %% 10000 == 0) message("Read ", i, " lines; kept ", k, " EU FSF orgs")
}

close(con)

df <- bind_rows(rows)
nrow(df)
head(df, 20)

write.csv(df, "/Users/reemarif/Desktop/eu_fsf_organizations.csv", row.names = FALSE)

```
```{r}
# pick one EU FSF org id
one_id <- df$id[1]

# re-read just that one entity from the big file (simple but works)
con <- file(path, open = "r")
found <- NULL
while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0) {
  x <- fromJSON(line, simplifyVector = FALSE)
  if (!is.null(x$id) && identical(x$id, one_id)) { found <- x; break }
}
close(con)

names(found$properties)
str(found$properties, max.level = 2)

```
```{r}
`%||%` <- function(x, y) if (is.null(x)) y else x

path <- "/Users/reemarif/Desktop/1st Quarter/MA Sources/Thesis-UC/entities.ftm (1).json"

con <- file(path, open = "r")
on.exit(close(con), add = TRUE)

rows <- list()
i <- 0
k <- 0

while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0) {
  i <- i + 1
  x <- fromJSON(line, simplifyVector = FALSE)

  if (identical(x$schema, "Organization")) {
    ds <- unlist(x$datasets %||% x$properties$datasets %||% character(), use.names = FALSE)

    pid <- unlist(x$properties$programId %||% character(), use.names = FALSE)

    # TEMP diagnostic: keep anything that mentions terrorism
    if (any(str_detect(tolower(pid), "terror|931"))) {
      k <- k + 1
      rows[[k]] <- tibble(
        id = x$id %||% NA_character_,
        name = x$caption %||% NA_character_,
        programId = paste(pid, collapse = "; "),
        sourceUrl = paste(unlist(x$properties$sourceUrl %||% character()), collapse = "; ")
      )
    }
  }

  if (i %% 20000 == 0) message("Read ", i, " lines; kept ", k)
}

df_terror <- bind_rows(rows)
nrow(df_terror)
head(df_terror)

```

```{r}

file.info("Gathering Data.Rmd")$size 


```

```{r}

`%||%` <- function(x, y) if (is.null(x)) y else x

path <- "/Users/reemarif/Desktop/entities.ftm.json"   # big file (keep outside repo)
out_csv <- "/Users/reemarif/Desktop/eu_terror_list_organizations.csv"

con <- file(path, open = "r")
on.exit(close(con), add = TRUE)

rows <- list()
k <- 0
i <- 0

# patterns that usually identify the EU terrorism regime
terror_prog_pat <- "terror|specific measures to combat terrorism|2580/2001|2580|2001/931|931"

while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0) {
  i <- i + 1
  x <- fromJSON(line, simplifyVector = FALSE)

  if (!identical(x$schema, "Organization")) next

  # quick topic filter (many terrorism entities have this)
  topics <- tolower(paste(unlist(x$properties$topics %||% character(), use.names = FALSE), collapse = " "))
  has_terror_topic <- str_detect(topics, "terror")

  sanc <- x$properties$sanctions
  if (is.null(sanc) && !has_terror_topic) next

  hit_programs <- character()

  if (!is.null(sanc)) {
    for (s in sanc) {
      program <- tolower(paste(unlist(s$program %||% character(), use.names = FALSE), collapse = " "))
      # we don’t require EU authority text here because your dump seems inconsistent on that;
      # instead we detect the EU terrorism regime by program wording.
      if (str_detect(program, terror_prog_pat)) {
        hit_programs <- c(hit_programs, paste(unlist(s$program %||% character(), use.names = FALSE), collapse = " · "))
      }
    }
  }

  hit_programs <- unique(hit_programs)

  # Keep org if it has an EU-terror style program hit OR at least a terror topic (fallback)
  if (length(hit_programs) > 0 || has_terror_topic) {
    k <- k + 1
    rows[[k]] <- tibble(
      id = x$id %||% NA_character_,
      name = x$caption %||% NA_character_,
      eu_terror_programs = if (length(hit_programs) > 0) paste(hit_programs, collapse = " | ") else NA_character_
    )
  }

  if (i %% 50000 == 0) message("Read ", i, " lines; kept ", k, " candidate terror orgs")
}

df_eu_terror <- bind_rows(rows) |>
  distinct(id, name, .keep_all = TRUE) |>
  arrange(name)

write.csv(df_eu_terror, out_csv, row.names = FALSE)
out_csv
```

```{r}
library(jsonlite)

path <- "/Users/reemarif/Desktop/entities.ftm.json"
con <- file(path, open = "r")
on.exit(close(con), add = TRUE)

i <- 0
found <- 0

while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0 && found < 5) {
  i <- i + 1
  x <- fromJSON(line, simplifyVector = FALSE)

  if (!identical(x$schema, "Organization")) next
  if (is.null(x$properties$sanctions)) next

  for (s in x$properties$sanctions) {
    prog <- paste(unlist(s$program %||% character(), use.names = FALSE), collapse = " ")
    if (nzchar(prog)) {
      cat("PROGRAM STRING:\n", prog, "\n\n")
      found <- found + 1
      break
    }
  }
}

cat("Stopped after", i, "lines\n")

```
```{r}

install.packages ("pdftools")
library(pdftools)

pdf_path <- "/Users/reemarif/Downloads/l_34020051223en00640066.pdf"  # update to your actual file path
out_csv  <- "/Users/reemarif/Desktop/eu_listed.csv"

txt <- paste(pdf_text(pdf_path), collapse = "\n")

# Grab the "Groups and entities" section chunk
m <- str_locate(txt, "Groups and entities")
if (any(is.na(m))) stop("Couldn't find 'Groups and entities' in this PDF text.")

chunk <- str_sub(txt, m[1,2], m[1,2] + 25000)

# Extract numbered entries: "1. Abu Nidal Organisation (ANO)..."
orgs <- str_extract_all(chunk, "\\n\\s*\\d+\\.\\s+[^\\n]+")[[1]] |>
  str_replace("^\\n\\s*\\d+\\.\\s+", "") |>
  str_squish()

df <- tibble(organization = orgs) |>
  distinct(organization) |>
  filter(organization != "")

write_csv(df, out_csv)
out_csv

```
```{r}

FSF <- jsonlite::stream_in(file("~/Desktop/FSF.json"), verbose = FALSE)
View(FSF)
```
```{r}
EU_UN <- FSF %>%
  filter(map_lgl(properties$programId, ~ "EU-TAQA-EUAQ" %in% .x)) |>
filter(schema == "Organization")
```
```{r}
EU_UN <- EU_UN  %>%
  mutate(
    Name = map_chr(properties$name, ~ paste(.x, collapse = "; ")),
    Alias = map_chr(properties$alias, ~ paste(.x, collapse = "; "), .default = NA),
    Program_ID = map_chr(properties$programId, ~ paste(.x, collapse = "; ")),
    Listing_Date = map_chr(properties$listingDate, ~ paste(.x, collapse = "; "), .default = NA),
    Notes = map_chr(properties$notes, ~ paste(.x, collapse = "; "), .default = NA)
  ) %>%
  select(caption, schema, Name, Alias, Listing_Date, Program_ID, Notes)
```

```{r}
EU_CP <- FSF %>%
  filter(map_lgl(properties$programId, ~ "EU-TERR" %in% .x)) %>%
  filter(schema == "Organization")
```

```{r}
EU_CP <- EU_CP %>%
  mutate(
    Name = map_chr(properties$name, ~ paste(.x, collapse = "; ")),
    Alias = map_chr(properties$alias, ~ paste(.x, collapse = "; "), .default = NA),
    Address = map_chr(properties$address, ~ paste(.x, collapse = "; "), .default = NA),
    Country = map_chr(properties$country, ~ paste(.x, collapse = "; "), .default = NA),
    Listing_Date = map_chr(properties$listingDate, ~ paste(.x, collapse = "; "), .default = NA),
    Notes = map_chr(properties$notes, ~ paste(.x, collapse = "; "), .default = NA)
  ) %>%
  select(Name, Alias, Address, Country, Listing_Date, Notes)
```





















